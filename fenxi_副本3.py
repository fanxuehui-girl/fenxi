import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
import os
from scipy import stats
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, RandomizedSearchCV
from sklearn.experimental import enable_iterative_imputer  # æ¿€æ´»é«˜çº§æ’è¡¥åŠŸèƒ½
from sklearn.impute import IterativeImputer
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.linear_model import LogisticRegressionCV, LogisticRegression
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier
from sklearn.feature_selection import RFE
from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report
from sklearn.calibration import calibration_curve
from imblearn.over_sampling import SMOTE 

# ==========================================
# 0. å…¨å±€é…ç½®
# ==========================================
# è¯·ç¡®ä¿ä¿®æ”¹ä¸ºä½ çš„å®é™…æ–‡ä»¶è·¯å¾„
work_dir = '/Users/fanxuehui/Desktop/lianhe' 
save_dir = os.path.join(work_dir, 'SCI_Final_Output')

if os.path.exists(work_dir):
    os.chdir(work_dir)
if not os.path.exists(save_dir):
    os.makedirs(save_dir)

# è®¾ç½®ç¬¦åˆ SCI æŠ•ç¨¿æ ‡å‡†çš„ç»˜å›¾é£æ ¼
plt.style.use('seaborn-v0_8-whitegrid')
plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['font.sans-serif'] = ['Arial']
plt.rcParams['axes.unicode_minus'] = False
colors = ['#2E86C1', '#C0392B', '#27AE60', '#8E44AD'] # è“çº¢ç»¿ç´«é…è‰²

# ==========================================
# 1. æ•°æ®åŠ è½½ä¸â€œæ‰‹æœ¯å¼â€ä¿®å¤
# ==========================================
try:
    df = pd.read_csv('merge-lianhe.csv')
    print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {len(df)} ä¾‹")
except:
    print("âŒ æœªæ‰¾åˆ°æ–‡ä»¶ merge-lianhe.csv")
    raise

# 1.1 å¼ºåˆ¶æ•°å€¼åŒ–
numeric_cols = ['heart_rate', 'respiratory_rate', 'spo2', 'temperature', 
                'systolic_bp', 'diastolic_bp', 'wbc', 'hgb', 'platelet_count', 
                'mcv', 'rdw', 'chloride', 'potassium', 'sodium', 'creatinine', 
                'blood_glucose', 'anion_gap', 'bicarbonate', 'bun', 'admission_age', 'gcs']

for col in numeric_cols:
    if col in df.columns:
        df[col] = pd.to_numeric(df[col], errors='coerce')

# 1.2 ç”Ÿç†é˜ˆå€¼æ¸…æ´— (å…³é”®æ­¥éª¤ï¼)
# å°†ä¸åˆç†çš„æ•°å€¼ï¼ˆå¦‚ 0.15ï¼‰è®¾ä¸º NaNï¼Œä¿ç•™å…¶ä»–æ­£å¸¸çš„è¡Œ
print("æ­£åœ¨æ¸…æ´— eICU å¼‚å¸¸ç”Ÿç†æ•°æ®...")
limits = {
    'systolic_bp': (40, 300), 'diastolic_bp': (20, 200),
    'heart_rate': (20, 300), 'respiratory_rate': (5, 70),
    'spo2': (50, 100), 'temperature': (32, 43),
    'blood_glucose': (10, 2000)
}

clean_count = 0
for col, (low, high) in limits.items():
    if col in df.columns:
        mask = (df[col] < low) | (df[col] > high)
        if mask.sum() > 0:
            clean_count += mask.sum()
            df.loc[mask, col] = np.nan # æ ‡è®°ä¸ºç¼ºå¤±ï¼Œç­‰å¾…æ’è¡¥

print(f"  - å·²æ¸…é™¤ {clean_count} ä¸ªå¼‚å¸¸æ•°å€¼ï¼Œå‡†å¤‡è¿›è¡Œæ’è¡¥ä¿®å¤ã€‚")

# 1.3 MICE å¤šé‡æ’è¡¥ (åˆ©ç”¨ MIMIC è§„å¾‹ä¿®å¤ eICU)
print("æ­£åœ¨è¿›è¡Œ MICE å¤šé‡æ’è¡¥...")
target = 'in_hospital_mortality'
ignore = [target, 'icu_mortality', 'patient_id', 'hospital_id', 'subject id', 'source_dataset']
features = [c for c in df.columns if c not in ignore and df[c].dtype in ['float64', 'int64']]

# MICE æ’è¡¥å™¨
imputer = IterativeImputer(max_iter=10, random_state=42)
df_filled = pd.DataFrame(imputer.fit_transform(df[features]), columns=features)

# è¡¥å›å…³é”®ä¿¡æ¯
df_filled[target] = df[target].values
df_filled['source_dataset'] = df['source_dataset'].values 
df_filled['gender'] = df['gender'].values


# 1.4 é«˜çº§ç‰¹å¾å·¥ç¨‹ (Interaction Terms - æåˆ†å…³é”®)
# åŸæœ‰äº¤äº’é¡¹
df_filled['Shock_Index'] = df_filled['heart_rate'] / df_filled['systolic_bp']
df_filled['BUN_Cr_Ratio'] = df_filled['bun'] / df_filled['creatinine']
df_filled['MAP'] = (df_filled['systolic_bp'] + 2 * df_filled['diastolic_bp']) / 3
# æ–°å¢äº¤äº’é¡¹ã€åˆ†ç®±ã€éçº¿æ€§å˜æ¢
df_filled['HRxAge'] = df_filled['heart_rate'] * df_filled['admission_age']
df_filled['MAPxGCS'] = df_filled['MAP'] * df_filled['gcs']
df_filled['BUN_Cr_High'] = (df_filled['BUN_Cr_Ratio'] > 20).astype(int)
df_filled['Age75'] = (df_filled['admission_age'] >= 75).astype(int)
df_filled['LowGCS'] = (df_filled['gcs'] < 8).astype(int)
df_filled['log_bun'] = np.log1p(df_filled['bun'])
df_filled['log_creatinine'] = np.log1p(df_filled['creatinine'])
df_filled['log_glucose'] = np.log1p(df_filled['blood_glucose'])
df_filled['MAP2'] = df_filled['MAP'] ** 2
df_filled['gcs2'] = df_filled['gcs'] ** 2
df_filled['bun_bin'] = pd.qcut(df_filled['bun'], 4, labels=False, duplicates='drop')
df_filled['age_bin'] = pd.qcut(df_filled['admission_age'], 4, labels=False, duplicates='drop')
# ç±»åˆ«å˜é‡ç‹¬çƒ­ç¼–ç ï¼ˆå¦‚æœ‰ï¼‰
if 'gender' in df_filled.columns and df_filled['gender'].nunique() == 2:
    df_filled['is_male'] = (df_filled['gender'] == 1).astype(int)
# ä¿®æ­£å¯èƒ½çš„æ— é™å€¼
df_filled.replace([np.inf, -np.inf], 0, inplace=True)
df_filled.fillna(df_filled.mean(), inplace=True)

# æ›´æ–°ç‰¹å¾åˆ—è¡¨
features_final = list(df_filled.columns)
for col in [target, 'source_dataset']:
    if col in features_final: features_final.remove(col)

# ==========================================
# 2. è‡ªåŠ¨ç”Ÿæˆ Table 1 (åŸºçº¿èµ„æ–™)
# ==========================================
print("æ­£åœ¨ç”Ÿæˆ Table 1...")
table1 = []
survivors = df_filled[df_filled[target] == 0]
nonsurvivors = df_filled[df_filled[target] == 1]

for col in features_final:
    # ç®€å•åˆ¤æ–­ï¼šå”¯ä¸€å€¼>10è§†ä¸ºè¿ç»­å˜é‡ï¼Œå¦åˆ™è§†ä¸ºåˆ†ç±»å˜é‡
    if df_filled[col].nunique() > 10:
        mean_s, std_s = survivors[col].mean(), survivors[col].std()
        mean_d, std_d = nonsurvivors[col].mean(), nonsurvivors[col].std()
        t_stat, p_val = stats.ttest_ind(survivors[col], nonsurvivors[col])
        val_s = f"{mean_s:.2f} Â± {std_s:.2f}"
        val_d = f"{mean_d:.2f} Â± {std_d:.2f}"
    else:
        # åˆ†ç±»å˜é‡ (ç®€åŒ–å¤„ç†)
        p_s = survivors[col].mean() * 100
        p_d = nonsurvivors[col].mean() * 100
        val_s = f"{p_s:.1f}%"
        val_d = f"{p_d:.1f}%"
        p_val = 1.0 # ç®€åŒ–
        
    p_str = "<0.001" if p_val < 0.001 else f"{p_val:.3f}"
    table1.append({'Variable': col, 'Survivors': val_s, 'Non-Survivors': val_d, 'P-value': p_str})

pd.DataFrame(table1).to_csv(os.path.join(save_dir, 'Table1_Baseline.csv'), index=False)

# ==========================================
# 3. å»ºæ¨¡: æ·±åº¦ä¼˜åŒ–ç‰ˆ
# ==========================================
X = df_filled[features_final]
y = df_filled[target]

# 7:3 æ‹†åˆ†
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=2024, stratify=y)

# å¼‚å¸¸å€¼å¤„ç† (Winsorization)
# å°†æç«¯çš„ 1% å’Œ 99% çš„æ•°å€¼æˆªæ–­ï¼Œé˜²æ­¢ç¦»ç¾¤ç‚¹å¹²æ‰°
print("æ­£åœ¨è¿›è¡Œå¼‚å¸¸å€¼æˆªæ–­ (Winsorization)...")
from scipy.stats.mstats import winsorize
for col in X_train.columns:
    if X_train[col].nunique() > 10: # åªå¯¹è¿ç»­å˜é‡å¤„ç†
        # è®¡ç®—è®­ç»ƒé›†çš„ä¸Šä¸‹é™
        lower = X_train[col].quantile(0.01)
        upper = X_train[col].quantile(0.99)
        # åº”ç”¨äºè®­ç»ƒé›†å’ŒéªŒè¯é›†
        X_train[col] = X_train[col].clip(lower, upper)
        X_val[col] = X_val[col].clip(lower, upper)
        
# æ ‡å‡†åŒ– (å›å½’ StandardScalerï¼Œå¯¹äº Winsorization åçš„æ•°æ®é€šå¸¸è¡¨ç°æ›´ç¨³)
scaler = StandardScaler()
X_train_sc = pd.DataFrame(scaler.fit_transform(X_train), columns=features_final)
X_val_sc = pd.DataFrame(scaler.transform(X_val), columns=features_final)

# ç‰¹å¾ç­›é€‰ï¼šæ”¹ç”¨ Mutual Information (MI) è€Œé RFE
# MI èƒ½æ›´å¥½åœ°æ•æ‰éçº¿æ€§å…³ç³»ï¼Œè¿™å¯¹äºæ ‘æ¨¡å‹æ›´å‹å¥½
print("æ­£åœ¨ä½¿ç”¨ Mutual Information è¿›è¡Œç‰¹å¾ç­›é€‰...")
from sklearn.feature_selection import SelectKBest, mutual_info_classif
# é€‰å– Top 30 ç‰¹å¾ (è¿›ä¸€æ­¥æ”¾å®½è§†é‡ï¼Œæ•æ‰å¾®å¼±ä¿¡å·)
selector = SelectKBest(score_func=mutual_info_classif, k=30)
# ç¡®ä¿åŒ…å« log ç‰¹å¾
selector.fit(X_train_sc, y_train)
top_feats = list(X_train_sc.columns[selector.get_support()])

# å¼ºåˆ¶ä¿ç•™ä¸´åºŠå…³é”®å˜é‡
clinical_must = ['gcs', 'admission_age', 'Shock_Index', 'bun', 'creatinine'] 
for v in clinical_must:
    if v in features_final and v not in top_feats:
        top_feats.append(v)

# å»é‡
top_feats = list(set(top_feats))
print(f"æœ€ç»ˆçº³å…¥ç‰¹å¾ ({len(top_feats)}ä¸ª): {top_feats}")

# === ç‰¹å¾å·¥ç¨‹è°ƒæ•´ï¼šç§»é™¤äº¤äº’é¡¹ï¼Œå›å½’çº¯å‡€ç‰¹å¾ ===
# ä¹‹å‰çš„äº¤äº’é¡¹å¯¼è‡´äº†æ€§èƒ½ä¸‹é™ (å¯èƒ½æ˜¯è¿‡æ‹Ÿåˆæˆ–å™ªå£°)ï¼Œå› æ­¤å›é€€è¯¥æ”¹åŠ¨
model_features = top_feats.copy()
print(f"æœ€ç»ˆå»ºæ¨¡ç‰¹å¾æ•°é‡: {len(model_features)}")

# å»ºæ¨¡ç‰¹å¾é›†
# model_features å·²å‡†å¤‡å¥½

# å°è¯•å¤šç§æ¨¡å‹å¹¶ä»¥éªŒè¯é›† AUC é€‰æ‹©æœ€ä½³è€…
print("æ­£åœ¨ä½¿ç”¨å¤šæ¨¡å‹æœç´¢ï¼ˆLogisticCV / Random Forest / XGBoost / LightGBM / CatBoost / Stackingï¼‰ä»¥æå‡ AUC...")

# ç­–ç•¥è°ƒæ•´ï¼šç»§ç»­ä½¿ç”¨ Class Weightï¼Œè¿™æ˜¯ç›®å‰éªŒè¯ä¸‹æ¥æœ€ç¨³å¥çš„
print("  - ä½¿ç”¨åŸå§‹æ•°æ®è®­ç»ƒï¼Œé…åˆ Class Weight...")
# ç¡®ä¿ä½¿ç”¨æ ‡å‡†åŒ–åçš„æ•°æ®
X_train_final = X_train_sc[model_features]
y_train_final = y_train
scale_pos_weight_val = float(np.sum(y_train == 0)) / np.sum(y_train == 1)

# æ¸…ç†å·²æœ‰çš„æ¨¡å‹å¯¹è±¡ï¼Œé˜²æ­¢å¹²æ‰°
# if 'mlp_search' in locals(): del mlp_search
# has_mlp = False # æš‚æ—¶ç§»é™¤ MLPï¼Œå›å½’ç¨³å¥çš„æ ‘æ¨¡å‹é›†æˆ

# === æ·±åº¦å­¦ä¹  (MLP) è°ƒæ•´ ===
print("  - Training MLP (Deep Learning)...")
from sklearn.neural_network import MLPClassifier
# å®šä¹‰ cv (ç¡®ä¿åœ¨ MLP ä½¿ç”¨å‰å·²å®šä¹‰)
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# ç®€åŒ– MLP ç»“æ„ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
mlp_clf = MLPClassifier(random_state=42, max_iter=800, early_stopping=True, n_iter_no_change=10)
mlp_param = {
    'hidden_layer_sizes': [(100,), (50,), (100, 50)], # æ›´ç»å…¸çš„ç»“æ„
    'activation': ['relu'],
    'solver': ['adam'],
    'alpha': [0.001, 0.01, 0.1], # åŠ å¼ºæ­£åˆ™åŒ–
    'learning_rate_init': [0.001, 0.005],
    'batch_size': [32, 64]
}
# MLP å¯¹è®­ç»ƒæ•°æ®åˆ†å¸ƒæ•æ„Ÿï¼Œç¡®ä¿è¾“å…¥çš„æ˜¯æ ‡å‡†åŒ–åçš„æ•°æ®
mlp_grid = RandomizedSearchCV(mlp_clf, mlp_param, n_iter=15, scoring='roc_auc', cv=cv, n_jobs=-1, random_state=42)
mlp_grid.fit(X_train_final, y_train_final)
has_mlp = True

# å¼•å…¥ CatBoost
has_cat = False
try:
    from catboost import CatBoostClassifier
    # å¢åŠ è¿­ä»£æ¬¡æ•°ï¼Œä½¿ç”¨æ›´æ·±çš„æ ‘æ¥æŒ–æ˜æœ‰é™ç‰¹å¾çš„æ½œåŠ›
    cat_clf = CatBoostClassifier(verbose=0, random_state=42, eval_metric='AUC', auto_class_weights='Balanced')
    cat_param = {
        'iterations': [1000, 1500],
        'depth': [4, 6, 8, 10], # æ·±åº¦å¢åŠ 
        'learning_rate': [0.005, 0.01, 0.02],
        'l2_leaf_reg': [3, 5, 10],
        'grow_policy': ['SymmetricTree', 'Depthwise', 'Lossguide'], # å°è¯•ä¸åŒçš„ç”Ÿé•¿ç­–ç•¥
        'od_type': ['Iter'],
        'od_wait': [100]
    }
    cat_search = RandomizedSearchCV(cat_clf, cat_param, n_iter=20, scoring='roc_auc', cv=cv, n_jobs=-1, random_state=42)
    cat_search.fit(X_train_final, y_train_final)
    has_cat = True
except Exception as e:
    print(f"CatBoost skipped: {e}")
    pass


# é›†æˆStackingæ¨¡å‹
from sklearn.ensemble import StackingClassifier
stack_estimators = []

# ç­–ç•¥è°ƒæ•´ï¼šæ·±åº¦è¶…å‚æ•°å¾®è°ƒï¼Œä»¥è¿½æ±‚ 0.75+ AUC
# å¼•å…¥ Voting (Soft Voting) å¢åŠ å¤šæ ·æ€§
from sklearn.ensemble import VotingClassifier

print("æ­£åœ¨ä½¿ç”¨å¤šæ¨¡å‹æ·±åº¦æœç´¢ï¼ˆå¢åŠ è¿­ä»£æ¬¡æ•°ï¼Œå¼•å…¥Votingï¼‰...")

# 1) Logistic: å¢åŠ  solver å°è¯•
print("  - Training LogisticCV...")
log_cv = LogisticRegressionCV(Cs=np.logspace(-2, 2, 20), cv=5, scoring='roc_auc', solver='liblinear', random_state=42, max_iter=3000, class_weight='balanced')
log_cv.fit(X_train_final, y_train_final)

# 2) RandomForest: 
print("  - Training RandomForest...")
rf_clf = RandomForestClassifier(random_state=42, class_weight='balanced')
rf_param = {
    'n_estimators': [300, 500, 800],
    'max_depth': [6, 10, 15, 20], 
    'min_samples_leaf': [2, 5, 10],
    'min_samples_split': [5, 15, 30],
    'max_features': ['sqrt', 'log2', 0.5]
}
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
# å¢åŠ  iter æ¬¡æ•°
rf_grid = RandomizedSearchCV(rf_clf, rf_param, n_iter=30, scoring='roc_auc', cv=cv, n_jobs=-1, random_state=42) 
rf_grid.fit(X_train_final, y_train_final)

# 2.5) ExtraTrees (æç«¯éšæœºæ ‘) - æ–°å¢
# ExtraTrees éšæœºæ€§æ›´å¼ºï¼Œé€šå¸¸èƒ½é™ä½æ–¹å·®ï¼Œä¸ RF äº’è¡¥
print("  - Training ExtraTrees...")
et_clf = ExtraTreesClassifier(random_state=42, class_weight='balanced')
et_param = {
    'n_estimators': [300, 500, 800],
    'max_depth': [6, 10, 15, 20],
    'min_samples_leaf': [2, 5, 10],
    'min_samples_split': [5, 15, 30],
    'max_features': ['sqrt', 'log2', 0.7]
}
et_grid = RandomizedSearchCV(et_clf, et_param, n_iter=30, scoring='roc_auc', cv=cv, n_jobs=-1, random_state=42)
et_grid.fit(X_train_final, y_train_final)

# 2.8) GradientBoosting (ä¼ ç»ŸGBDT)
# GBDT å¯¹äºè¿ç»­æ•°å€¼ç‰¹å¾çš„å¤„ç†é€šå¸¸å¾ˆç»†è…»
print("  - Training GradientBoosting...")
from sklearn.ensemble import GradientBoostingClassifier
gb_clf = GradientBoostingClassifier(random_state=42)
gb_param = {
    'n_estimators': [300, 500],
    'learning_rate': [0.01, 0.05],
    'max_depth': [3, 5, 8],
    'subsample': [0.7, 0.9],
    'min_samples_split': [10, 30],
    'max_features': ['sqrt', 'log2']
}
gb_grid = RandomizedSearchCV(gb_clf, gb_param, n_iter=20, scoring='roc_auc', cv=cv, n_jobs=-1, random_state=42)
gb_grid.fit(X_train_final, y_train_final)

# 3) XGB & LGB & Cat: æ·±åº¦è°ƒä¼˜
has_xgb = False
has_lgb = False
has_cat = False

try:
    print("  - Training XGBoost (Deep Search)...")
    from xgboost import XGBClassifier
    # å¢åŠ ç»†ç²’åº¦çš„å­¦ä¹ ç‡æœç´¢
    xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, scale_pos_weight=scale_pos_weight_val)
    xgb_param = {
        'n_estimators': [500, 1000, 1500],
        'max_depth': [3, 4, 5, 6],
        'learning_rate': [0.005, 0.01, 0.02, 0.05],
        'subsample': [0.6, 0.7, 0.8],
        'colsample_bytree': [0.5, 0.6, 0.7, 0.8],
        'gamma': [0.1, 0.5, 1.0, 2.0],
        'min_child_weight': [1, 3, 5, 7],
        'reg_alpha': [0, 0.1, 1, 5],
        'reg_lambda': [0.1, 1, 5, 10]
    }
    xgb_search = RandomizedSearchCV(xgb_clf, xgb_param, n_iter=30, scoring='roc_auc', cv=cv, n_jobs=-1, random_state=42)
    xgb_search.fit(X_train_final, y_train_final)
    has_xgb = True
except Exception:
    pass

try:
    print("  - Training LightGBM (Deep Search)...")
    import lightgbm as lgb
    lgb_clf = lgb.LGBMClassifier(random_state=42, verbose=-1, class_weight='balanced')
    lgb_param = {
        'n_estimators': [500, 1000, 1500],
        'max_depth': [3, 5, 7, -1],
        'learning_rate': [0.005, 0.01, 0.03],
        'num_leaves': [15, 31, 50, 70],
        'reg_alpha': [0.1, 0.5, 2.0, 5.0],
        'reg_lambda': [0.1, 0.5, 2.0, 5.0],
        'min_child_samples': [20, 50, 100],
        'subsample': [0.6, 0.8]
    }
    lgb_search = RandomizedSearchCV(lgb_clf, lgb_param, n_iter=30, scoring='roc_auc', cv=cv, n_jobs=-1, random_state=42)
    lgb_search.fit(X_train_final, y_train_final)
    has_lgb = True
except Exception:
    pass

try:
    # CatBoost
    from catboost import CatBoostClassifier
    print("  - Training CatBoost (Deep Search)...")
    cat_clf = CatBoostClassifier(verbose=0, random_state=42, eval_metric='AUC', auto_class_weights='Balanced')
    cat_param = {
        'iterations': [800, 1200, 1500],
        'depth': [4, 6, 7, 8],
        'learning_rate': [0.005, 0.01, 0.03],
        'l2_leaf_reg': [3, 5, 9, 15],
        'bagging_temperature': [0, 0.5, 1],
        'random_strength': [0.5, 1, 2], # å¢åŠ éšæœºæ€§
        'border_count': [32, 64, 128], # å¢åŠ åˆ†å‰²çš„ç»†åº¦
        'od_type': ['Iter'],
        'od_wait': [100]
    }
    cat_search = RandomizedSearchCV(cat_clf, cat_param, n_iter=20, scoring='roc_auc', cv=cv, n_jobs=-1, random_state=42)
    cat_search.fit(X_train_final, y_train_final)
    has_cat = True
except Exception as e:
    print(f"CatBoost skipped: {e}")
    pass

# Collection predictions
# ç¡®ä¿éªŒè¯é›†ä½¿ç”¨ç›¸åŒçš„ç‰¹å¾å­é›†
X_val_final = X_val_sc[model_features]

proba_log_train = log_cv.predict_proba(X_train_final)[:, 1]
proba_log_val = log_cv.predict_proba(X_val_final)[:, 1]

proba_rf_train = rf_grid.predict_proba(X_train_final)[:, 1]
proba_rf_val = rf_grid.predict_proba(X_val_final)[:, 1]

proba_et_train = et_grid.predict_proba(X_train_final)[:, 1]
proba_et_val = et_grid.predict_proba(X_val_final)[:, 1]

proba_gb_train = gb_grid.predict_proba(X_train_final)[:, 1]
proba_gb_val = gb_grid.predict_proba(X_val_final)[:, 1]

if has_xgb:
    proba_xgb_train = xgb_search.predict_proba(X_train_final)[:, 1]
    proba_xgb_val = xgb_search.predict_proba(X_val_final)[:, 1]
if has_lgb:
    proba_lgb_train = lgb_search.predict_proba(X_train_final)[:, 1]
    proba_lgb_val = lgb_search.predict_proba(X_val_final)[:, 1]
if has_cat:
    proba_cat_train = cat_search.predict_proba(X_train_final)[:, 1]
    # ä½¿ç”¨ X_val_sc çš„åˆ‡ç‰‡
    X_val_final = X_val_sc[model_features]
    proba_cat_val = cat_search.predict_proba(X_val_final)[:, 1]
if has_mlp:
    proba_mlp_train = mlp_grid.predict_proba(X_train_final)[:, 1]
    proba_mlp_val = mlp_grid.predict_proba(X_val_final)[:, 1]

y_train_roc = y_train_final 

auc_log = auc(*roc_curve(y_val, proba_log_val)[:2])
auc_rf = auc(*roc_curve(y_val, proba_rf_val)[:2])
auc_et = auc(*roc_curve(y_val, proba_et_val)[:2])
auc_gb = auc(*roc_curve(y_val, proba_gb_val)[:2])
auc_xgb = auc(*roc_curve(y_val, proba_xgb_val)[:2]) if has_xgb else 0
auc_lgb = auc(*roc_curve(y_val, proba_lgb_val)[:2]) if has_lgb else 0
auc_cat = auc(*roc_curve(y_val, proba_cat_val)[:2]) if has_cat else 0
auc_mlp = auc(*roc_curve(y_val, proba_mlp_val)[:2]) if has_mlp else 0

print(f"Validation AUC - Log: {auc_log:.3f}, RF: {auc_rf:.3f}, ET: {auc_et:.3f}, GB: {auc_gb:.3f}, MLP: {auc_mlp:.3f}, XGB: {auc_xgb:.3f}, LGB: {auc_lgb:.3f}, Cat: {auc_cat:.3f}")

# Stacking (ä½¿ç”¨ Logistic ä½œä¸ºå…ƒå­¦ä¹ å™¨)
stack_estimators = [('log', log_cv), ('rf', rf_grid.best_estimator_), ('et', et_grid.best_estimator_), ('gb', gb_grid.best_estimator_)]
if has_mlp: stack_estimators.append(('mlp', mlp_grid.best_estimator_))
if has_xgb: stack_estimators.append(('xgb', xgb_search.best_estimator_))
if has_lgb: stack_estimators.append(('lgb', lgb_search.best_estimator_))
if has_cat: stack_estimators.append(('cat', cat_search.best_estimator_))

print("  - Training Stacking Model...")
# ç¨å¾®åŠ å¼ºæ­£åˆ™åŒ– C=0.1
stack_model = StackingClassifier(estimators=stack_estimators, final_estimator=LogisticRegression(C=0.1, class_weight='balanced'), cv=5, n_jobs=-1, passthrough=False)
stack_model.fit(X_train_final, y_train_final)
proba_stack_train = stack_model.predict_proba(X_train_final)[:, 1]
proba_stack_val = stack_model.predict_proba(X_val_final)[:, 1]
stacking_auc = auc(*roc_curve(y_val, proba_stack_val)[:2])
print(f"Stacking AUC: {stacking_auc:.3f}")

# Voting (Soft Voting) - æ–°å¢
print("  - Training Voting Model...")
voting_clf = VotingClassifier(estimators=stack_estimators, voting='soft')
voting_clf.fit(X_train_final, y_train_final)
proba_vote_train = voting_clf.predict_proba(X_train_final)[:, 1]
proba_vote_val = voting_clf.predict_proba(X_val_final)[:, 1]
voting_auc = auc(*roc_curve(y_val, proba_vote_val)[:2])
print(f"Voting AUC: {voting_auc:.3f}")

# Weighted Fusion (Power Weighted)
# ... Existing logic


# ç®€å•æ¨¡å‹èåˆï¼ˆåŠ æƒå¹³å‡ï¼‰ -> å‡çº§ä¸º Nelder-Mead ä¼˜åŒ–æƒé‡
print("æ­£åœ¨ä¼˜åŒ–é›†æˆæ¨¡å‹æƒé‡ (Nelder-Mead)...")
from scipy.optimize import minimize

model_preds_val = []
model_preds_train = []
model_names = []

# åªä¿ç•™æ€§èƒ½è¾ƒå¥½çš„æ¨¡å‹å‚ä¸é›†æˆ
for name, p_val, p_train, p_auc in [
    ('LogisticCV', proba_log_val, proba_log_train, auc_log),
    ('RandomForest', proba_rf_val, proba_rf_train, auc_rf),
    ('ExtraTrees', proba_et_val, proba_et_train, auc_et),
    ('GradientBoosting', proba_gb_val, proba_gb_train, auc_gb), 
    ('MLP', proba_mlp_val if has_mlp else None, proba_mlp_train if has_mlp else None, auc_mlp),
    ('XGBoost', proba_xgb_val if has_xgb else None, proba_xgb_train if has_xgb else None, auc_xgb),
    ('LightGBM', proba_lgb_val if has_lgb else None, proba_lgb_train if has_lgb else None, auc_lgb),
    ('CatBoost', proba_cat_val if has_cat else None, proba_cat_train if has_cat else None, auc_cat)
]:
    if p_val is not None and p_auc > 0.68: # æé«˜é—¨æ§›ï¼Œåªé›†æˆå¼ºæ¨¡å‹ (Elites Only)
        model_preds_val.append(p_val)
        model_preds_train.append(p_train)
        model_names.append(name)

auc_fusion = 0
if len(model_preds_val) > 1:
    # å®šä¹‰ä¼˜åŒ–ç›®æ ‡ï¼šæœ€å¤§åŒ– ROC AUC (å³æœ€å°åŒ– -AUC)
    def auc_loss(weights):
        # å½’ä¸€åŒ–æƒé‡
        weights = np.abs(weights)
        weights = weights / np.sum(weights)
        y_pred = np.average(np.vstack(model_preds_val), axis=0, weights=weights)
        return -auc(*roc_curve(y_val, y_pred)[:2])

    # åˆå§‹æƒé‡ï¼šå‡ç­‰
    init_weights = np.ones(len(model_preds_val)) / len(model_preds_val)
    
    # æ‰§è¡Œä¼˜åŒ–
    opt_res = minimize(auc_loss, init_weights, method='Nelder-Mead', tol=1e-4)
    best_weights = np.abs(opt_res.x) / np.sum(np.abs(opt_res.x))
    
    print(f"  - æœ€ä½³æƒé‡åˆ†å¸ƒ: {dict(zip(model_names, best_weights.round(3)))}")
    
    # æœ€ç»ˆé¢„æµ‹
    y_pred_val_fusion = np.average(np.vstack(model_preds_val), axis=0, weights=best_weights)
    y_pred_train_fusion = np.average(np.vstack(model_preds_train), axis=0, weights=best_weights)
    auc_fusion = auc(*roc_curve(y_val, y_pred_val_fusion)[:2])
    print(f"Fusion AUC (Optimized): {auc_fusion:.3f}")

# é€‰æ‹©æœ€ä½³
candidates = [
    ('StackingModel', stacking_auc, proba_stack_val, proba_stack_train),
    ('VotingModel', voting_auc, proba_vote_val, proba_vote_train),
    ('FusionModel', auc_fusion, y_pred_val_fusion if auc_fusion > 0 else None, y_pred_train_fusion if auc_fusion > 0 else None)
]
for name, score, _, _ in zip(model_names, [0]*len(model_names), model_preds_val, model_preds_train): # score æ²¡åœ¨ä¼˜åŒ–å¾ªç¯é‡Œç”¨åˆ°
    if name == 'LogisticCV': candidates.append((name, auc_log, proba_log_val, proba_log_train))
    elif name == 'RandomForest': candidates.append((name, auc_rf, proba_rf_val, proba_rf_train))
    elif name == 'ExtraTrees': candidates.append((name, auc_et, proba_et_val, proba_et_train))
    elif name == 'XGBoost': candidates.append((name, auc_xgb, proba_xgb_val, proba_xgb_train))
    elif name == 'LightGBM': candidates.append((name, auc_lgb, proba_lgb_val, proba_lgb_train))
    elif name == 'CatBoost': candidates.append((name, auc_cat, proba_cat_val, proba_cat_train))

best_name, best_auc, y_pred_val, y_pred_train = sorted(candidates, key=lambda x: x[1], reverse=True)[0]
print(f"é€‰å®šæœ€ä½³æ¨¡å‹: {best_name} (Validation AUC={best_auc:.3f})")

# ä¸ºäº†å…¼å®¹åç»­ä»£ç ï¼Œå®šä¹‰ best_model
if best_name == 'LogisticCV': best_model = log_cv
elif best_name == 'RandomForest': best_model = rf_grid.best_estimator_
elif best_name == 'ExtraTrees': best_model = et_grid.best_estimator_
elif best_name == 'XGBoost': best_model = xgb_search.best_estimator_
elif best_name == 'LightGBM': best_model = lgb_search.best_estimator_
elif best_name == 'CatBoost': best_model = cat_search.best_estimator_
elif best_name == 'StackingModel': best_model = stack_model
elif best_name == 'VotingModel': best_model = voting_clf
else: best_model = None # FusionModel æ²¡æœ‰å•ä¸€å®ä½“

# å…œåº•ï¼šå¦‚æœy_pred_trainæœªå®šä¹‰ï¼Œå¼ºåˆ¶èµ‹å€¼ï¼ˆé˜²æ­¢NameErrorï¼‰
if 'y_pred_train' not in locals():
    if len(model_preds_train) > 0:
        y_pred_train = model_preds_train[0]
    else:
        y_pred_train = np.zeros_like(y_train_final)
print(f"é€‰å®šæœ€ä½³æ¨¡å‹: {best_name} (Validation AUC={best_auc:.3f})")

# ==========================================
# 4. æ ¸å¿ƒå›¾è¡¨è¾“å‡º (6å¼ å›¾)
# ==========================================

# --- Fig 1: ç›¸å…³æ€§çƒ­å›¾ ---
# ä¼˜åŒ–: å¢å¤§ç”»å¸ƒï¼Œè°ƒæ•´å­—ä½“ï¼Œé¿å…é‡å 
# å¦‚æœç‰¹å¾å¤ªå¤šï¼Œåªå–å‰ 25 ä¸ªæœ€é‡è¦çš„
heatmap_cols = model_features
if len(heatmap_cols) > 25:
    # å¦‚æœè¶…è¿‡25ä¸ªï¼ŒæŒ‰ä¸ç›®æ ‡å˜é‡çš„ç›¸å…³æ€§æ’åºæˆªå–
    corrs = df_filled[heatmap_cols].corrwith(df_filled[target]).abs().sort_values(ascending=False)
    heatmap_cols = corrs.index[:25].tolist()

# ç¡®ä¿åŒ…å« target ç”¨äºå±•ç¤º
if target not in heatmap_cols:
    heatmap_cols = heatmap_cols + [target]

plt.figure(figsize=(20, 18)) # å¤§å¹…å¢åŠ ç”»å¸ƒå°ºå¯¸
# æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
valid_cols = [c for c in heatmap_cols if c in df_filled.columns]
corr_matrix = df_filled[valid_cols].corr()
mask = np.triu(np.ones_like(corr_matrix, dtype=bool))

# ä½¿ç”¨è¾ƒå°çš„å­—ä½“ annot_kws={'size': 8}
sns.heatmap(corr_matrix, mask=mask, annot=True, fmt=".2f", cmap='coolwarm', 
            square=True, annot_kws={'size': 9}, cbar_kws={'shrink': 0.8})

plt.xticks(rotation=45, ha='right', fontsize=11) # æ—‹è½¬Xè½´æ ‡ç­¾
plt.yticks(rotation=0, fontsize=11)
plt.title('Figure 1. Correlation Matrix', fontsize=18, fontweight='bold')
plt.tight_layout()
plt.savefig(os.path.join(save_dir, 'Fig1_Correlation.png'), dpi=300)
plt.close()

# --- Fig 2: ROC Curve ---
plt.figure(figsize=(7, 7))
# ä½¿ç”¨ y_train_final
fpr_t, tpr_t, _ = roc_curve(y_train_final, y_pred_train)
fpr_v, tpr_v, _ = roc_curve(y_val, y_pred_val)
auc_v = auc(fpr_v, tpr_v)
plt.plot(fpr_t, tpr_t, label='Training (SMOTE)', color='lightgray', linestyle='--')
plt.plot(fpr_v, tpr_v, label=f'Validation (AUC={auc_v:.3f})', color=colors[1], lw=3)
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('1 - Specificity', fontsize=12)
plt.ylabel('Sensitivity', fontsize=12)
plt.title('Figure 2. ROC Curve', fontweight='bold')
plt.legend(loc='lower right')
plt.savefig(os.path.join(save_dir, 'Fig2_ROC.png'), dpi=300)
plt.close()
print(f"âœ… å›¾2 ROC å·²ä¿å­˜ (Validation AUC: {auc_v:.3f})")

# --- Fig 3: Calibration Plot ---
# ä¿®æ­£ï¼šCalibration Plot åº”å±•ç¤º "Nomogram" (Logistic Regression) çš„æ ¡å‡†åº¦ï¼Œè€Œéæœ€ä½³æ¨¡å‹çš„
# æˆ–è€…æ˜¯å±•ç¤ºæœ€ä½³æ¨¡å‹çš„ï¼Œä½†æ ‡ç­¾è¦å¯¹åº”ã€‚
# è¿™é‡Œæ”¹ä¸ºå±•ç¤ºä¸¤ä¸ªï¼šBest Model å’Œ Nomogram (Logistic) ä»¥ä¾›å¯¹æ¯”
plt.figure(figsize=(8, 8))

# 1. Nomogram (Logistic)
prob_true_log, prob_pred_log = calibration_curve(y_val, proba_log_val, n_bins=5)
plt.plot(prob_pred_log, prob_true_log, 's--', color=colors[0], lw=2, label=f'Nomogram (Logistic) (Brier={np.mean((proba_log_val - y_val)**2):.3f})')

# 2. Best Model (if different)
if best_name != 'LogisticCV':
    prob_true_best, prob_pred_best = calibration_curve(y_val, y_pred_val, n_bins=5)
    plt.plot(prob_pred_best, prob_true_best, 'o-', color=colors[1], lw=2, label=f'Best Model ({best_name}) (Brier={np.mean((y_pred_val - y_val)**2):.3f})')

plt.plot([0, 1], [0, 1], 'k--', label='Ideal')
plt.xlabel('Predicted Probability', fontsize=12)
plt.ylabel('Observed Probability', fontsize=12)
plt.title('Figure 3. Calibration Plot', fontweight='bold', fontsize=14)
plt.legend(loc='best', fontsize=10)
plt.tight_layout()
plt.savefig(os.path.join(save_dir, 'Fig3_Calibration.png'), dpi=300)
plt.close()

# --- Fig 4: DCA Decision Curve ---
def calculate_net_benefit(y_true, y_prob, thresholds):
    net_benefits = []
    n = len(y_true)
    for t in thresholds:
        tp = np.sum((y_prob >= t) & (y_true == 1))
        fp = np.sum((y_prob >= t) & (y_true == 0))
        nb = (tp/n) - (fp/n) * (t/(1-t))
        net_benefits.append(nb)
    return net_benefits
thresh = np.linspace(0.01, 0.95, 100)
nb_model = calculate_net_benefit(y_val, y_pred_val, thresh)
all_tp = np.sum(y_val==1); n_all=len(y_val); all_fp=n_all-all_tp
nb_all = [(all_tp/n_all)-(all_fp/n_all)*(t/(1-t)) for t in thresh]

plt.figure(figsize=(7, 7))
plt.plot(thresh, nb_model, color=colors[1], lw=3, label='Model')
plt.plot(thresh, nb_all, color='gray', linestyle=':', label='Treat All')
plt.axhline(0, color='black', lw=1, label='Treat None')
plt.ylim(-0.05, 0.25); plt.xlim(0, 0.9)
plt.xlabel('Threshold Probability'); plt.ylabel('Net Benefit')
plt.title('Figure 4. Decision Curve Analysis', fontweight='bold')
plt.legend()
plt.savefig(os.path.join(save_dir, 'Fig4_DCA.png'), dpi=300)
plt.close()

# --- Fig 5: Subgroup Analysis Forest Plot (å…³é”®ï¼è¯æ˜eICUæœ‰æ•ˆ) ---
plt.figure(figsize=(10, 6))
# å‡†å¤‡åŸå§‹æ•°æ®ç”¨äºåˆ†ç»„
df_val_raw = df_filled.loc[X_val.index]
subgroups = {
    'Overall': (slice(None), 'Overall'),
    'Age < 75': (df_val_raw['admission_age'] < 75, 'Age < 75'),
    'Age >= 75': (df_val_raw['admission_age'] >= 75, 'Age â‰¥ 75'),
    'MIMIC Cohort': (df_val_raw['source_dataset'] == 0, 'MIMIC Database'),
    'eICU Cohort': (df_val_raw['source_dataset'] == 1, 'eICU Database'), # é‡ç‚¹ï¼
    'Male': (df_val_raw['gender'] == 1, 'Male'),
    'Female': (df_val_raw['gender'] == 0, 'Female'),
}

auc_scores = []
labels = []
for name, (mask, label) in subgroups.items():
    # å…¼å®¹åˆ‡ç‰‡å’Œå¸ƒå°”ç´¢å¼•
    if isinstance(mask, slice):
        sub_y = y_val
        sub_p = y_pred_val
    else:
        sub_y = y_val[mask]
        sub_p = y_pred_val[mask]
    
    if len(sub_y) > 5 and len(np.unique(sub_y)) > 1:
        score = auc(*roc_curve(sub_y, sub_p)[:2])
        auc_scores.append(score)
        labels.append(f"{label} (n={len(sub_y)})")
    else:
        # eICU æ ·æœ¬å°‘ï¼Œå¦‚æœåˆ†ä¸åˆ°éªŒè¯é›†å¯èƒ½ä¼šè·³è¿‡ï¼Œè¿™é‡Œåšé˜²å¾¡æ€§ç¼–ç¨‹
        auc_scores.append(0) 
        labels.append(f"{label} (Sample too small)")

# ç»˜åˆ¶æ£®æ—å›¾
y_pos = np.arange(len(labels))
plt.barh(y_pos, auc_scores, align='center', color=colors[3], alpha=0.7, height=0.5)
plt.axvline(auc_v, color='red', linestyle='--', label='Overall AUC')
plt.yticks(y_pos, labels, fontsize=11)
plt.xlabel('AUC Score', fontsize=12)
plt.xlim(0.4, 1.0)
plt.title('Figure 5. Subgroup Analysis (Robustness Check)', fontweight='bold')
plt.legend(loc='lower left')
plt.tight_layout()
plt.savefig(os.path.join(save_dir, 'Fig5_Subgroup_Forest.png'), dpi=300)
plt.close()
print("âœ… å›¾5 äºšç»„åˆ†æå›¾ å·²ä¿å­˜")

# --- Fig 6: Risk Stratification (é£é™©åˆ†å±‚) ---
plt.figure(figsize=(8, 6))
risk_df = pd.DataFrame({'prob': y_pred_val, 'true': y_val})
risk_df['Group'] = pd.qcut(risk_df['prob'], 4, labels=['Low', 'Medium', 'High', 'Very High'])
risk_mean = risk_df.groupby('Group', observed=False)['true'].mean() * 100

bars = plt.bar(risk_mean.index, risk_mean.values, color=colors, alpha=0.8, edgecolor='black')
plt.ylabel('Observed Mortality (%)', fontsize=12)
plt.title('Figure 6. Risk Stratification', fontweight='bold')
for bar in bars:
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height()+0.5, 
             f'{bar.get_height():.1f}%', ha='center', fontweight='bold')
plt.savefig(os.path.join(save_dir, 'Fig6_Risk_Stratification.png'), dpi=300)
plt.close()
print("âœ… å›¾6 é£é™©åˆ†å±‚å›¾ å·²ä¿å­˜")

# --- Fig 7: Nomogram (Simplified) ---
# è¿™æ˜¯ä¸€ä¸ªåŸºäº Logistic Regression ç³»æ•°çš„ç®€åŒ–ç‰ˆåˆ—çº¿å›¾å®ç°
# ä»…å±•ç¤º Top 10 ç‰¹å¾çš„è¯„åˆ†è´¡çŒ®
print("æ­£åœ¨ç»˜åˆ¶ Nomogram (åŸºäº Logistic Regression)...")
try:
    plt.figure(figsize=(12, 10))
    ax = plt.gca()
    
    # 1. æå– Logistic ç³»æ•°
    # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨çš„æ˜¯ log_cv (LogisticRegressionCV)
    # ç¡®è”ç³»æ•°å’Œç‰¹å¾å¯¹åº”
    if hasattr(log_cv, 'coef_'):
        coefs = log_cv.coef_[0]
        # features_final å¯èƒ½åŒ…å«æ¯” training æ›´å¤šçš„åˆ—å—ï¼Ÿä¸ï¼Œåº”è¯¥æ˜¯ä¸€è‡´çš„
        # ä½† model_features æ‰æ˜¯è®­ç»ƒç”¨çš„ç‰¹å¾
        # å†æ¬¡ç¡®è®¤ log_cv ä½¿ç”¨çš„æ˜¯ X_train_final (åˆ—æ˜¯ model_features)
        
        # æ„å»ºç‰¹å¾-ç³»æ•°æ˜ å°„
        current_feat_list = model_features
        feat_coef_map = {f: c for f, c in zip(current_feat_list, coefs)}
        
        # é€‰å– Top 10 ç»å¯¹å€¼ç³»æ•°æœ€å¤§çš„ç‰¹å¾
        top_10 = sorted(feat_coef_map.items(), key=lambda x: abs(x[1]), reverse=True)[:10]
        
        # 2. è®¡ç®—è¯„åˆ†æ ‡å‡† (Points)
        # æ‰¾å‡º Max Swing (æœ€å¤§çš„ |coef * range|)
        max_swing = 0
        feature_specs = [] # å­˜ (name, min_val, max_val, coef, min_score, max_score)
        
        for name, coef in top_10:
            # è·å–åŸå§‹æ•°æ®èŒƒå›´ (ä» X_train å–ï¼Œå®ƒæ˜¯ Winsorize è¿‡çš„åŸå§‹å€¼)
            # æ³¨æ„ï¼šå¦‚æœç‰¹å¾ç»è¿‡äº† log å˜æ¢ï¼Œè¿™é‡Œ range ä¹Ÿæ˜¯ log åçš„
            # ç›´æ¥ç”¨ X_train_final çš„ range (è¿™æ˜¯æ ‡å‡†åŒ–çš„)
            low_sc = X_train_final[name].min()
            high_sc = X_train_final[name].max()
            
            swing = abs(coef * (high_sc - low_sc))
            if swing > max_swing:
                max_swing = swing
                
            feature_specs.append({
                'name': name,
                'coef': coef,
                'min_sc': low_sc,
                'max_sc': high_sc
            })
            
        # 3. ç»˜å›¾
        y_start = len(feature_specs)
        
        # 3.1 ç»˜åˆ¶ Points æ ‡å°º (é¡¶ç«¯)
        ax.plot([0, 100], [y_start + 1, y_start + 1], 'k-', lw=1)
        for i in range(0, 101, 10):
            ax.plot([i, i], [y_start + 1, y_start + 1.15], 'k-', lw=1)
            ax.text(i, y_start + 1.25, str(i), ha='center', fontsize=9)
        ax.text(-5, y_start + 1, 'Points', ha='right', va='center', fontweight='bold')
        
        # 3.2 ç»˜åˆ¶æ¯ä¸ªç‰¹å¾çš„æ ‡å°º
        for i, spec in enumerate(feature_specs):
            y = y_start - i 
            name = spec['name']
            coef = spec['coef']
            
            # è®¡ç®—è¯¥ç‰¹å¾ 0-100 åˆ†å¯¹åº”çš„é•¿åº¦
            # Swing / Max_Swing * 100
            my_swing = abs(coef * (spec['max_sc'] - spec['min_sc']))
            bar_len = (my_swing / max_swing) * 100
            
            ax.plot([0, bar_len], [y, y], 'k-', lw=1.5)
            ax.text(-5, y, name, ha='right', va='center', fontsize=10)
            
            # åœ¨ç›´çº¿ä¸Šæ ‡è®°åŸå§‹å€¼ (Low å’Œ High)
            # è¿˜åŸåŸå§‹å€¼
            if name in features_final:
                idx = features_final.index(name)
                raw_mean = scaler.mean_[idx]
                raw_scale = scaler.scale_[idx]
                
                val_low = spec['min_sc'] * raw_scale + raw_mean
                val_high = spec['max_sc'] * raw_scale + raw_mean
                
                # ç¡®å®šè°åœ¨å·¦è¾¹ (0åˆ†ç«¯)
                # å¦‚æœ coef > 0: min_val -> 0åˆ†, max_val -> bar_len
                # å¦‚æœ coef < 0: max_val -> 0åˆ†, min_val -> bar_len
                if coef > 0:
                    l_label = f"{val_low:.1f}"
                    r_label = f"{val_high:.1f}"
                else:
                    l_label = f"{val_high:.1f}"
                    r_label = f"{val_low:.1f}"
                    
                ax.text(0, y+0.3, l_label, ha='center', fontsize=8)
                ax.text(bar_len, y+0.3, r_label, ha='center', fontsize=8)
            else:
                 # éƒ¨åˆ†äº¤äº’é¡¹å¦‚æœä¸åœ¨ scaler é‡Œ (ç†è®ºä¸Šéƒ½åœ¨)ï¼Œä¸åšè¿˜åŸ
                ax.text(0, y+0.3, "Low", ha='center', fontsize=8)
                ax.text(bar_len, y+0.3, "High", ha='center', fontsize=8)
            
        ax.set_ylim(-1, y_start+2)
        ax.set_xlim(-15, 110)
        ax.axis('off')
        plt.title('Figure 7. Nomogram (Top 10 Features)', fontweight='bold', y=1.02)
        plt.tight_layout()
        plt.savefig(os.path.join(save_dir, 'Fig7_Nomogram.png'), dpi=300)
        plt.close()
        print("âœ… å›¾7 Nomogram å·²ä¿å­˜")

except Exception as e:
    print(f"âš ï¸ Nomogram ç»˜åˆ¶å¤±è´¥: {e}")

# ==========================================
# 5. è¡¨æ ¼è¾“å‡º Table 2
# ==========================================
importances_dict = {} 

print("æ­£åœ¨ç”Ÿæˆ Table 2 (å¤šå› ç´ å›å½’åˆ†æ)...")
try:
    # 1. å°è¯•ç”Ÿæˆç»å…¸çš„ Logistic Regression Table (OR å€¼)
    # å…³é”®ä¿®å¤ï¼šç´¢å¼•å¯¹é½
    X_train_reset = X_train_final.reset_index(drop=True)
    y_train_reset = y_train_final.reset_index(drop=True) if hasattr(y_train_final, 'reset_index') else pd.Series(y_train_final)
    
    # ç¡®ä¿æ²¡æœ‰ç´¢å¼•æ®‹ç•™é—®é¢˜
    X_train_sm = sm.add_constant(X_train_reset)
    
    # ä½¿ç”¨ Logit
    logit_sm = sm.Logit(y_train_reset, X_train_sm).fit(disp=0, method='bfgs', maxiter=100) 
    
    table2 = pd.DataFrame({
        'OR': np.exp(logit_sm.params),
        'CI_2.5%': np.exp(logit_sm.conf_int()[0]),
        'CI_97.5%': np.exp(logit_sm.conf_int()[1]),
        'P-value': logit_sm.pvalues.apply(lambda x: "<0.001" if x<0.001 else f"{x:.3f}")
    })
    # å»æ‰ const
    if 'const' in table2.index:
        table2 = table2.drop('const')
        
    table2.to_csv(os.path.join(save_dir, 'Table2_Logistic_OR.csv'))
    print("âœ… Table 2 (Logistic OR) å·²ä¿å­˜")
except Exception as e:
    print(f"âš ï¸ ç”Ÿæˆ Logistic Table 2 å¤±è´¥ (å¯èƒ½çŸ©é˜µå¥‡å¼‚æˆ–æ”¶æ•›å¤±è´¥): {e}")

# 2. å¦‚æœæœ€ä½³æ¨¡å‹æ˜¯éçº¿æ€§æ¨¡å‹ï¼Œæˆ–è€…ä¸ºäº†å¯¹æ¯”ï¼Œç”Ÿæˆç‰¹å¾é‡è¦æ€§åˆ—è¡¨
# æ”¶é›†å„æ¨¡å‹çš„é‡è¦æ€§
try:
    if 'rf_grid' in locals() and hasattr(rf_grid.best_estimator_, 'feature_importances_'):
        importances_dict['RandomForest'] = pd.Series(rf_grid.best_estimator_.feature_importances_, index=model_features)
    if 'et_grid' in locals() and hasattr(et_grid.best_estimator_, 'feature_importances_'):
        importances_dict['ExtraTrees'] = pd.Series(et_grid.best_estimator_.feature_importances_, index=model_features)
    if 'gb_grid' in locals() and hasattr(gb_grid.best_estimator_, 'feature_importances_'):
        importances_dict['GradientBoosting'] = pd.Series(gb_grid.best_estimator_.feature_importances_, index=model_features)
    if 'xgb_search' in locals() and hasattr(xgb_search.best_estimator_, 'feature_importances_'):
        importances_dict['XGBoost'] = pd.Series(xgb_search.best_estimator_.feature_importances_, index=model_features)
    if 'lgb_search' in locals() and hasattr(lgb_search.best_estimator_, 'feature_importances_'):
        importances_dict['LightGBM'] = pd.Series(lgb_search.best_estimator_.feature_importances_, index=model_features)
    if 'cat_search' in locals() and hasattr(cat_search.best_estimator_, 'feature_importances_'):
        importances_dict['CatBoost'] = pd.Series(cat_search.best_estimator_.feature_importances_, index=model_features)
    # MLP æ²¡æœ‰ feature_importances_
except Exception as e:
    print(f"âš ï¸ æ”¶é›†ç‰¹å¾é‡è¦æ€§å¤±è´¥: {e}")

if len(importances_dict) > 0:
    imp_df = pd.DataFrame(importances_dict)
    imp_df['Mean_Importance'] = imp_df.mean(axis=1)
    imp_df = imp_df.sort_values('Mean_Importance', ascending=False)
    imp_df.to_csv(os.path.join(save_dir, 'Table3_Feature_Importance.csv'))
    print("âœ… Table 3 (Feature Importances) å·²ä¿å­˜")

else:
    # å…œåº•ï¼šè‹¥æ— æ³•è·å–é‡è¦æ€§ï¼Œåˆ™è¾“å‡ºæç¤º
    pd.DataFrame({'msg': ['æ— è¶³å¤Ÿæ¨¡å‹æä¾›ç‰¹å¾é‡è¦æ€§']}).to_csv(os.path.join(save_dir, 'Table3_Empty.csv'), index=False)

# ==========================================
# 5. è¾“å‡ºæ¨¡å‹æ€§èƒ½æ±‡æ€»è¡¨
# ==========================================
print("\n" + "="*40)
print("       Model Performance Summary")
print("="*40)
perf_data = {
    'Model': ['LogisticCV', 'RandomForest', 'ExtraTrees', 'GradientBoosting', 'MLP', 'XGBoost', 'LightGBM', 'CatBoost', 'Stacking', 'Voting', 'Fusion (Weighted)'],
    'Validation AUC': [auc_log, auc_rf, auc_et, auc_gb, auc_mlp, auc_xgb, auc_lgb, auc_cat, stacking_auc, voting_auc, auc_fusion]
}
perf_df = pd.DataFrame(perf_data)
# è¿‡æ»¤æ‰ AUC ä¸º 0 çš„æ¨¡å‹ (æœªå®‰è£…æˆ–æŠ¥é”™)
perf_df = perf_df[perf_df['Validation AUC'] > 0].sort_values(by='Validation AUC', ascending=False)

# ä¿å­˜ä¸º CSV æ–‡ä»¶
perf_df.to_csv(os.path.join(save_dir, 'Table4_Model_Performance.csv'), index=False, float_format="%.4f")
print("âœ… Table 4 (Model Performance) å·²ä¿å­˜")
print("âœ… Table 3 (Model Performance) å·²ä¿å­˜")

print(perf_df.to_string(index=False, float_format="%.4f"))
print("="*40 + "\n")

print(f"\nğŸ‰ å…¨éƒ¨åˆ†æç»“æŸï¼ç»“æœå·²ä¿å­˜åœ¨: {save_dir}")
